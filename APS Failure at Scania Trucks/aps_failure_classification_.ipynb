{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d60eed43",
   "metadata": {},
   "source": [
    "##### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4897f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a40506",
   "metadata": {},
   "source": [
    "##### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64c9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/aps_failure_training_set_processed_8bit.csv')\n",
    "train_labels = pd.read_csv('dataset/aps_failure_training_set.csv')['class']\n",
    "\n",
    "test_df = pd.read_csv('dataset/aps_failure_test_set_processed_8bit.csv')\n",
    "test_labels = pd.read_csv('dataset/aps_failure_test_set.csv')['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd11b0ff",
   "metadata": {},
   "source": [
    "##### Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5797e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['class'] = train_labels\n",
    "test_df['class'] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2de2e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=5885e32d-2867-4aaf-b6be-89779c72347d style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('5885e32d-2867-4aaf-b6be-89779c72347d').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>-0.109375</td>\n",
       "      <td>-0.140625</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>-0.179688</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>-0.148438</td>\n",
       "      <td>-0.085938</td>\n",
       "      <td>-0.140625</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140625</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.109375</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>-0.164062</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.351562</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.992188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>-0.039062</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>-0.148438</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "  class    aa_000    ab_000    ac_000    ad_000    ae_000    af_000    ag_000  \\\n",
       "0   neg  0.117188 -0.289062  0.992188 -0.007812 -0.046875 -0.054688 -0.007812   \n",
       "1   neg -0.179688 -0.289062 -0.468750 -0.007812 -0.046875 -0.054688 -0.007812   \n",
       "2   neg -0.125000 -0.289062 -0.468750 -0.007812 -0.046875 -0.054688 -0.007812   \n",
       "3   neg -0.406250 -0.289062 -0.468750 -0.007812 -0.046875 -0.007812 -0.007812   \n",
       "4   neg  0.007812 -0.289062 -0.468750 -0.007812 -0.046875 -0.054688 -0.007812   \n",
       "\n",
       "    ag_001    ag_002  ...    ee_002    ee_003    ee_004    ee_005    ee_006  \\\n",
       "0 -0.03125 -0.054688  ...  0.687500  0.515625  0.234375  0.070312  0.007812   \n",
       "1 -0.03125 -0.054688  ... -0.023438 -0.062500 -0.132812 -0.132812 -0.187500   \n",
       "2 -0.03125 -0.054688  ... -0.140625 -0.093750 -0.015625  0.015625 -0.007812   \n",
       "3 -0.03125 -0.054688  ... -0.382812 -0.382812 -0.375000 -0.351562 -0.312500   \n",
       "4 -0.03125 -0.054688  ...  0.156250  0.031250 -0.031250 -0.039062 -0.046875   \n",
       "\n",
       "     ee_007    ee_008    ee_009    ef_000    eg_000  \n",
       "0 -0.109375 -0.140625 -0.171875 -0.023438 -0.023438  \n",
       "1 -0.148438 -0.085938 -0.140625 -0.023438 -0.023438  \n",
       "2 -0.109375 -0.093750 -0.164062 -0.023438 -0.023438  \n",
       "3 -0.195312 -0.304688 -0.171875  0.890625  0.992188  \n",
       "4 -0.015625  0.656250 -0.148438 -0.023438 -0.023438  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13ee8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=8f09bff9-b485-4acc-9136-13709cedbb57 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('8f09bff9-b485-4acc-9136-13709cedbb57').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.46875</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.351562</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.46875</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.351562</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>-0.46875</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.109375</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>-0.109375</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.46875</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.320312</td>\n",
       "      <td>-0.109375</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>-0.390625</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.46875</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.359375</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "  class    aa_000    ab_000   ac_000    ad_000    ae_000    af_000    ag_000  \\\n",
       "0   neg -0.406250 -0.289062 -0.46875 -0.007812 -0.046875 -0.054688 -0.007812   \n",
       "1   neg -0.406250 -0.289062 -0.46875 -0.007812 -0.046875 -0.054688 -0.007812   \n",
       "2   neg  0.046875  0.554688 -0.46875 -0.007812 -0.046875 -0.054688 -0.007812   \n",
       "3   neg  0.000000 -0.289062 -0.46875 -0.007812 -0.046875 -0.054688 -0.007812   \n",
       "4   neg -0.390625 -0.289062 -0.46875 -0.007812 -0.046875 -0.054688 -0.007812   \n",
       "\n",
       "    ag_001    ag_002  ...    ee_002    ee_003    ee_004    ee_005    ee_006  \\\n",
       "0 -0.03125 -0.054688  ... -0.382812 -0.382812 -0.375000 -0.351562 -0.312500   \n",
       "1 -0.03125 -0.054688  ... -0.382812 -0.382812 -0.375000 -0.351562 -0.312500   \n",
       "2 -0.03125 -0.054688  ...  0.046875  0.312500 -0.000000 -0.109375  0.914062   \n",
       "3 -0.03125 -0.054688  ...  0.085938  0.062500  0.031250  0.085938  0.093750   \n",
       "4 -0.03125 -0.054688  ... -0.375000 -0.375000 -0.359375 -0.304688 -0.304688   \n",
       "\n",
       "     ee_007    ee_008    ee_009    ef_000    eg_000  \n",
       "0 -0.195312 -0.304688 -0.171875 -0.023438 -0.023438  \n",
       "1 -0.195312 -0.304688 -0.171875 -0.023438 -0.023438  \n",
       "2 -0.109375 -0.304688 -0.171875 -0.023438 -0.023438  \n",
       "3 -0.078125  0.320312 -0.109375 -0.023438 -0.023438  \n",
       "4 -0.195312 -0.304688 -0.171875 -0.023438 -0.023438  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "770b25f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=b5b6bab8-9d9a-456f-8404-5626509fe8a8 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('b5b6bab8-9d9a-456f-8404-5626509fe8a8').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.124611</td>\n",
       "      <td>-0.071121</td>\n",
       "      <td>-0.198529</td>\n",
       "      <td>-0.007737</td>\n",
       "      <td>-0.033483</td>\n",
       "      <td>-0.040633</td>\n",
       "      <td>-0.006584</td>\n",
       "      <td>-0.026241</td>\n",
       "      <td>-0.040699</td>\n",
       "      <td>-0.074768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104808</td>\n",
       "      <td>-0.098734</td>\n",
       "      <td>-0.094976</td>\n",
       "      <td>-0.089227</td>\n",
       "      <td>-0.103374</td>\n",
       "      <td>-0.088961</td>\n",
       "      <td>-0.084540</td>\n",
       "      <td>-0.067471</td>\n",
       "      <td>-0.020035</td>\n",
       "      <td>-0.018417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.367680</td>\n",
       "      <td>0.356812</td>\n",
       "      <td>0.564872</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.107086</td>\n",
       "      <td>0.111752</td>\n",
       "      <td>0.032016</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.105864</td>\n",
       "      <td>0.186822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356547</td>\n",
       "      <td>0.362066</td>\n",
       "      <td>0.363148</td>\n",
       "      <td>0.336121</td>\n",
       "      <td>0.320314</td>\n",
       "      <td>0.237613</td>\n",
       "      <td>0.363893</td>\n",
       "      <td>0.261009</td>\n",
       "      <td>0.051907</td>\n",
       "      <td>0.061751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.117188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.351562</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.398438</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.117188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.343750</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.117188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179688</td>\n",
       "      <td>-0.179688</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.179688</td>\n",
       "      <td>-0.226562</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.296875</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.070312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.117188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.101562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "             aa_000        ab_000        ac_000        ad_000        ae_000  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean      -0.124611     -0.071121     -0.198529     -0.007737     -0.033483   \n",
       "std        0.367680      0.356812      0.564872      0.004138      0.107086   \n",
       "min       -0.406250     -0.289062     -0.468750     -0.007812     -0.046875   \n",
       "25%       -0.398438     -0.289062     -0.468750     -0.007812     -0.046875   \n",
       "50%       -0.195312     -0.289062     -0.468750     -0.007812     -0.046875   \n",
       "75%       -0.070312      0.000000     -0.468750     -0.007812     -0.046875   \n",
       "max        0.992188      0.992188      0.992188      0.992188      0.992188   \n",
       "\n",
       "             af_000        ag_000        ag_001        ag_002        ag_003  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean      -0.040633     -0.006584     -0.026241     -0.040699     -0.074768   \n",
       "std        0.111752      0.032016      0.065200      0.105864      0.186822   \n",
       "min       -0.054688     -0.007812     -0.031250     -0.054688     -0.117188   \n",
       "25%       -0.054688     -0.007812     -0.031250     -0.054688     -0.117188   \n",
       "50%       -0.054688     -0.007812     -0.031250     -0.054688     -0.117188   \n",
       "75%       -0.054688     -0.007812     -0.031250     -0.054688     -0.117188   \n",
       "max        0.992188      0.992188      0.992188      0.992188      0.992188   \n",
       "\n",
       "       ...        ee_002        ee_003        ee_004        ee_005  \\\n",
       "count  ...  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean   ...     -0.104808     -0.098734     -0.094976     -0.089227   \n",
       "std    ...      0.356547      0.362066      0.363148      0.336121   \n",
       "min    ...     -0.382812     -0.382812     -0.382812     -0.351562   \n",
       "25%    ...     -0.382812     -0.382812     -0.375000     -0.343750   \n",
       "50%    ...     -0.179688     -0.179688     -0.195312     -0.179688   \n",
       "75%    ...     -0.007812      0.015625      0.015625      0.007812   \n",
       "max    ...      0.992188      0.992188      0.992188      0.992188   \n",
       "\n",
       "             ee_006        ee_007        ee_008        ee_009        ef_000  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean      -0.103374     -0.088961     -0.084540     -0.067471     -0.020035   \n",
       "std        0.320314      0.237613      0.363893      0.261009      0.051907   \n",
       "min       -0.312500     -0.195312     -0.304688     -0.171875     -0.023438   \n",
       "25%       -0.312500     -0.195312     -0.304688     -0.171875     -0.023438   \n",
       "50%       -0.226562     -0.171875     -0.296875     -0.171875     -0.023438   \n",
       "75%       -0.054688     -0.101562      0.000000     -0.132812     -0.023438   \n",
       "max        0.992188      0.992188      0.992188      0.992188      0.992188   \n",
       "\n",
       "             eg_000  \n",
       "count  60000.000000  \n",
       "mean      -0.018417  \n",
       "std        0.061751  \n",
       "min       -0.023438  \n",
       "25%       -0.023438  \n",
       "50%       -0.023438  \n",
       "75%       -0.023438  \n",
       "max        0.992188  \n",
       "\n",
       "[8 rows x 170 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "487a8811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=7003df8f-15a4-4168-b415-d7a9ee403852 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('7003df8f-15a4-4168-b415-d7a9ee403852').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>59000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.124611</td>\n",
       "      <td>-0.071121</td>\n",
       "      <td>-0.198529</td>\n",
       "      <td>-0.007737</td>\n",
       "      <td>-0.033483</td>\n",
       "      <td>-0.040633</td>\n",
       "      <td>-0.006584</td>\n",
       "      <td>-0.026241</td>\n",
       "      <td>-0.040699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104808</td>\n",
       "      <td>-0.098734</td>\n",
       "      <td>-0.094976</td>\n",
       "      <td>-0.089227</td>\n",
       "      <td>-0.103374</td>\n",
       "      <td>-0.088961</td>\n",
       "      <td>-0.084540</td>\n",
       "      <td>-0.067471</td>\n",
       "      <td>-0.020035</td>\n",
       "      <td>-0.018417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.351562</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.398438</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.343750</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179688</td>\n",
       "      <td>-0.179688</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.179688</td>\n",
       "      <td>-0.226562</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.296875</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.070312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.101562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "        class        aa_000        ab_000        ac_000        ad_000  \\\n",
       "count   60000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "unique      2           NaN           NaN           NaN           NaN   \n",
       "top       neg           NaN           NaN           NaN           NaN   \n",
       "freq    59000           NaN           NaN           NaN           NaN   \n",
       "mean      NaN     -0.124611     -0.071121     -0.198529     -0.007737   \n",
       "std       NaN      0.367680      0.356812      0.564872      0.004138   \n",
       "min       NaN     -0.406250     -0.289062     -0.468750     -0.007812   \n",
       "25%       NaN     -0.398438     -0.289062     -0.468750     -0.007812   \n",
       "50%       NaN     -0.195312     -0.289062     -0.468750     -0.007812   \n",
       "75%       NaN     -0.070312      0.000000     -0.468750     -0.007812   \n",
       "max       NaN      0.992188      0.992188      0.992188      0.992188   \n",
       "\n",
       "              ae_000        af_000        ag_000        ag_001        ag_002  \\\n",
       "count   60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean       -0.033483     -0.040633     -0.006584     -0.026241     -0.040699   \n",
       "std         0.107086      0.111752      0.032016      0.065200      0.105864   \n",
       "min        -0.046875     -0.054688     -0.007812     -0.031250     -0.054688   \n",
       "25%        -0.046875     -0.054688     -0.007812     -0.031250     -0.054688   \n",
       "50%        -0.046875     -0.054688     -0.007812     -0.031250     -0.054688   \n",
       "75%        -0.046875     -0.054688     -0.007812     -0.031250     -0.054688   \n",
       "max         0.992188      0.992188      0.992188      0.992188      0.992188   \n",
       "\n",
       "        ...        ee_002        ee_003        ee_004        ee_005  \\\n",
       "count   ...  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "unique  ...           NaN           NaN           NaN           NaN   \n",
       "top     ...           NaN           NaN           NaN           NaN   \n",
       "freq    ...           NaN           NaN           NaN           NaN   \n",
       "mean    ...     -0.104808     -0.098734     -0.094976     -0.089227   \n",
       "std     ...      0.356547      0.362066      0.363148      0.336121   \n",
       "min     ...     -0.382812     -0.382812     -0.382812     -0.351562   \n",
       "25%     ...     -0.382812     -0.382812     -0.375000     -0.343750   \n",
       "50%     ...     -0.179688     -0.179688     -0.195312     -0.179688   \n",
       "75%     ...     -0.007812      0.015625      0.015625      0.007812   \n",
       "max     ...      0.992188      0.992188      0.992188      0.992188   \n",
       "\n",
       "              ee_006        ee_007        ee_008        ee_009        ef_000  \\\n",
       "count   60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean       -0.103374     -0.088961     -0.084540     -0.067471     -0.020035   \n",
       "std         0.320314      0.237613      0.363893      0.261009      0.051907   \n",
       "min        -0.312500     -0.195312     -0.304688     -0.171875     -0.023438   \n",
       "25%        -0.312500     -0.195312     -0.304688     -0.171875     -0.023438   \n",
       "50%        -0.226562     -0.171875     -0.296875     -0.171875     -0.023438   \n",
       "75%        -0.054688     -0.101562      0.000000     -0.132812     -0.023438   \n",
       "max         0.992188      0.992188      0.992188      0.992188      0.992188   \n",
       "\n",
       "              eg_000  \n",
       "count   60000.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean       -0.018417  \n",
       "std         0.061751  \n",
       "min        -0.023438  \n",
       "25%        -0.023438  \n",
       "50%        -0.023438  \n",
       "75%        -0.023438  \n",
       "max         0.992188  \n",
       "\n",
       "[11 rows x 171 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cf10c4",
   "metadata": {},
   "source": [
    "##### Checking the Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ba98668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class     0\n",
       "aa_000    0\n",
       "ab_000    0\n",
       "ac_000    0\n",
       "ad_000    0\n",
       "         ..\n",
       "ee_007    0\n",
       "ee_008    0\n",
       "ee_009    0\n",
       "ef_000    0\n",
       "eg_000    0\n",
       "Length: 171, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f134078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=89006923-0a6c-4e69-9850-5b728f945d9b style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('89006923-0a6c-4e69-9850-5b728f945d9b').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa_000</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.121999</td>\n",
       "      <td>0.091271</td>\n",
       "      <td>0.025188</td>\n",
       "      <td>0.110415</td>\n",
       "      <td>0.115131</td>\n",
       "      <td>0.067289</td>\n",
       "      <td>0.185408</td>\n",
       "      <td>0.327367</td>\n",
       "      <td>0.490721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867362</td>\n",
       "      <td>0.861476</td>\n",
       "      <td>0.839020</td>\n",
       "      <td>0.839522</td>\n",
       "      <td>0.823592</td>\n",
       "      <td>0.714641</td>\n",
       "      <td>0.488417</td>\n",
       "      <td>0.302424</td>\n",
       "      <td>0.048662</td>\n",
       "      <td>0.025319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_000</th>\n",
       "      <td>0.121999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015372</td>\n",
       "      <td>0.011020</td>\n",
       "      <td>-0.017268</td>\n",
       "      <td>-0.016700</td>\n",
       "      <td>0.016740</td>\n",
       "      <td>0.042054</td>\n",
       "      <td>0.064040</td>\n",
       "      <td>0.076730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139755</td>\n",
       "      <td>0.124066</td>\n",
       "      <td>0.115553</td>\n",
       "      <td>0.118397</td>\n",
       "      <td>0.103143</td>\n",
       "      <td>0.103732</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.021730</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.004143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ac_000</th>\n",
       "      <td>0.091271</td>\n",
       "      <td>0.015372</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.007997</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.021513</td>\n",
       "      <td>0.022585</td>\n",
       "      <td>0.022782</td>\n",
       "      <td>0.020065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102385</td>\n",
       "      <td>0.104665</td>\n",
       "      <td>0.097855</td>\n",
       "      <td>0.097390</td>\n",
       "      <td>0.083394</td>\n",
       "      <td>0.066857</td>\n",
       "      <td>0.072585</td>\n",
       "      <td>0.047044</td>\n",
       "      <td>0.011207</td>\n",
       "      <td>0.017086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad_000</th>\n",
       "      <td>0.025188</td>\n",
       "      <td>0.011020</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001366</td>\n",
       "      <td>-0.001411</td>\n",
       "      <td>0.006440</td>\n",
       "      <td>0.016721</td>\n",
       "      <td>0.017864</td>\n",
       "      <td>0.014560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028775</td>\n",
       "      <td>0.023424</td>\n",
       "      <td>0.020111</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.013391</td>\n",
       "      <td>0.015753</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ae_000</th>\n",
       "      <td>0.110415</td>\n",
       "      <td>-0.017268</td>\n",
       "      <td>0.007997</td>\n",
       "      <td>-0.001366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966834</td>\n",
       "      <td>-0.004659</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.037658</td>\n",
       "      <td>0.138005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037365</td>\n",
       "      <td>0.046288</td>\n",
       "      <td>0.029458</td>\n",
       "      <td>0.050052</td>\n",
       "      <td>0.177118</td>\n",
       "      <td>0.124427</td>\n",
       "      <td>-0.058660</td>\n",
       "      <td>-0.049432</td>\n",
       "      <td>0.221157</td>\n",
       "      <td>0.204498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ee_007</th>\n",
       "      <td>0.714641</td>\n",
       "      <td>0.103732</td>\n",
       "      <td>0.066857</td>\n",
       "      <td>0.015753</td>\n",
       "      <td>0.124427</td>\n",
       "      <td>0.128893</td>\n",
       "      <td>0.043951</td>\n",
       "      <td>0.160518</td>\n",
       "      <td>0.354358</td>\n",
       "      <td>0.601018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595695</td>\n",
       "      <td>0.580086</td>\n",
       "      <td>0.556076</td>\n",
       "      <td>0.600210</td>\n",
       "      <td>0.766848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.374890</td>\n",
       "      <td>0.187208</td>\n",
       "      <td>0.036857</td>\n",
       "      <td>0.017779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ee_008</th>\n",
       "      <td>0.488417</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.072585</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>-0.058660</td>\n",
       "      <td>-0.057943</td>\n",
       "      <td>0.017027</td>\n",
       "      <td>0.021267</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.018597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480937</td>\n",
       "      <td>0.482618</td>\n",
       "      <td>0.449890</td>\n",
       "      <td>0.473259</td>\n",
       "      <td>0.483717</td>\n",
       "      <td>0.374890</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780811</td>\n",
       "      <td>-0.025096</td>\n",
       "      <td>-0.035292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ee_009</th>\n",
       "      <td>0.302424</td>\n",
       "      <td>0.021730</td>\n",
       "      <td>0.047044</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>-0.049432</td>\n",
       "      <td>-0.049671</td>\n",
       "      <td>-0.000373</td>\n",
       "      <td>-0.020576</td>\n",
       "      <td>-0.045709</td>\n",
       "      <td>-0.081193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295910</td>\n",
       "      <td>0.292490</td>\n",
       "      <td>0.266447</td>\n",
       "      <td>0.272294</td>\n",
       "      <td>0.268450</td>\n",
       "      <td>0.187208</td>\n",
       "      <td>0.780811</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018435</td>\n",
       "      <td>-0.024006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ef_000</th>\n",
       "      <td>0.048662</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.011207</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.221157</td>\n",
       "      <td>0.218371</td>\n",
       "      <td>0.004524</td>\n",
       "      <td>0.019810</td>\n",
       "      <td>0.047570</td>\n",
       "      <td>0.080130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019257</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>0.021801</td>\n",
       "      <td>0.046217</td>\n",
       "      <td>0.036857</td>\n",
       "      <td>-0.025096</td>\n",
       "      <td>-0.018435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eg_000</th>\n",
       "      <td>0.025319</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.017086</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.204498</td>\n",
       "      <td>0.202610</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.030623</td>\n",
       "      <td>0.055827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002936</td>\n",
       "      <td>-0.002632</td>\n",
       "      <td>-0.011163</td>\n",
       "      <td>0.004524</td>\n",
       "      <td>0.034035</td>\n",
       "      <td>0.017779</td>\n",
       "      <td>-0.035292</td>\n",
       "      <td>-0.024006</td>\n",
       "      <td>0.632963</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "          aa_000    ab_000    ac_000    ad_000    ae_000    af_000    ag_000  \\\n",
       "aa_000  1.000000  0.121999  0.091271  0.025188  0.110415  0.115131  0.067289   \n",
       "ab_000  0.121999  1.000000  0.015372  0.011020 -0.017268 -0.016700  0.016740   \n",
       "ac_000  0.091271  0.015372  1.000000  0.005124  0.007997  0.007327  0.021513   \n",
       "ad_000  0.025188  0.011020  0.005124  1.000000 -0.001366 -0.001411  0.006440   \n",
       "ae_000  0.110415 -0.017268  0.007997 -0.001366  1.000000  0.966834 -0.004659   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "ee_007  0.714641  0.103732  0.066857  0.015753  0.124427  0.128893  0.043951   \n",
       "ee_008  0.488417  0.034100  0.072585  0.004279 -0.058660 -0.057943  0.017027   \n",
       "ee_009  0.302424  0.021730  0.047044  0.003246 -0.049432 -0.049671 -0.000373   \n",
       "ef_000  0.048662  0.011490  0.011207  0.000651  0.221157  0.218371  0.004524   \n",
       "eg_000  0.025319  0.004143  0.017086  0.000069  0.204498  0.202610  0.002599   \n",
       "\n",
       "          ag_001    ag_002    ag_003  ...    ee_002    ee_003    ee_004  \\\n",
       "aa_000  0.185408  0.327367  0.490721  ...  0.867362  0.861476  0.839020   \n",
       "ab_000  0.042054  0.064040  0.076730  ...  0.139755  0.124066  0.115553   \n",
       "ac_000  0.022585  0.022782  0.020065  ...  0.102385  0.104665  0.097855   \n",
       "ad_000  0.016721  0.017864  0.014560  ...  0.028775  0.023424  0.020111   \n",
       "ae_000  0.000273  0.037658  0.138005  ...  0.037365  0.046288  0.029458   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "ee_007  0.160518  0.354358  0.601018  ...  0.595695  0.580086  0.556076   \n",
       "ee_008  0.021267  0.024793  0.018597  ...  0.480937  0.482618  0.449890   \n",
       "ee_009 -0.020576 -0.045709 -0.081193  ...  0.295910  0.292490  0.266447   \n",
       "ef_000  0.019810  0.047570  0.080130  ...  0.019257  0.017986  0.010572   \n",
       "eg_000  0.007825  0.030623  0.055827  ... -0.002936 -0.002632 -0.011163   \n",
       "\n",
       "          ee_005    ee_006    ee_007    ee_008    ee_009    ef_000    eg_000  \n",
       "aa_000  0.839522  0.823592  0.714641  0.488417  0.302424  0.048662  0.025319  \n",
       "ab_000  0.118397  0.103143  0.103732  0.034100  0.021730  0.011490  0.004143  \n",
       "ac_000  0.097390  0.083394  0.066857  0.072585  0.047044  0.011207  0.017086  \n",
       "ad_000  0.016272  0.013391  0.015753  0.004279  0.003246  0.000651  0.000069  \n",
       "ae_000  0.050052  0.177118  0.124427 -0.058660 -0.049432  0.221157  0.204498  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "ee_007  0.600210  0.766848  1.000000  0.374890  0.187208  0.036857  0.017779  \n",
       "ee_008  0.473259  0.483717  0.374890  1.000000  0.780811 -0.025096 -0.035292  \n",
       "ee_009  0.272294  0.268450  0.187208  0.780811  1.000000 -0.018435 -0.024006  \n",
       "ef_000  0.021801  0.046217  0.036857 -0.025096 -0.018435  1.000000  0.632963  \n",
       "eg_000  0.004524  0.034035  0.017779 -0.035292 -0.024006  0.632963  1.000000  \n",
       "\n",
       "[170 rows x 170 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be2e8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop('class', axis=1)\n",
    "Y = train_df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ca489",
   "metadata": {},
   "source": [
    "##### Splitting into Train & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3e15afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1059e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (60000, 171)\n",
      "Train Shape: (42000, 170)\n",
      "Test Shape: (18000, 170)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Shape: {}\".format(train_df.shape))\n",
    "print(\"Train Shape: {}\".format(X_train.shape))\n",
    "print(\"Test Shape: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d85ff43",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "994e1e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac58028c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.12%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: {:.2f}%\".format(log_reg.score(X_test, y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d57cec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model on test set (Cost = $ 0.99):\n",
      "Best model cost per truck on test set (Cost = $ 0.00)\n"
     ]
    }
   ],
   "source": [
    "test_score = log_reg.score(X_test, y_test)\n",
    "test_score_per_truck = test_score/X_test.shape[0]\n",
    "\n",
    "print(\"Best model on test set (Cost = $ %0.2f):\" % test_score)\n",
    "print(\"Best model cost per truck on test set (Cost = $ %0.2f)\" % test_score_per_truck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16edd2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68be49ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9911666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "accuracy_score(y_test, y_pred_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "805e439c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.99      1.00      1.00     17702\n",
      "         pos       0.82      0.60      0.69       298\n",
      "\n",
      "    accuracy                           0.99     18000\n",
      "   macro avg       0.91      0.80      0.84     18000\n",
      "weighted avg       0.99      0.99      0.99     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e5cfa9",
   "metadata": {},
   "source": [
    "##### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e16e748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "714ba298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9887777777777778"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dt = dt.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bda7a3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.99      0.99      0.99     17702\n",
      "         pos       0.66      0.65      0.66       298\n",
      "\n",
      "    accuracy                           0.99     18000\n",
      "   macro avg       0.83      0.82      0.83     18000\n",
      "weighted avg       0.99      0.99      0.99     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b893bc",
   "metadata": {},
   "source": [
    "##### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7de28b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "clf = SVC(C = 1.2, gamma =  0.9, kernel= 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b68a7775",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train,y_train)\n",
    "y_pred_svc = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c74bd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.98      1.00      0.99     17702\n",
      "         pos       1.00      0.04      0.07       298\n",
      "\n",
      "    accuracy                           0.98     18000\n",
      "   macro avg       0.99      0.52      0.53     18000\n",
      "weighted avg       0.98      0.98      0.98     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05817420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9840555555555556"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675d09ed",
   "metadata": {},
   "source": [
    "##### Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "002547f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5400015",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_model = ExtraTreeClassifier()\n",
    "extra_model.fit(X,Y)\n",
    "feature_imp = extra_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00253e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.99\n",
      "1 0.27\n",
      "2 0.7\n",
      "3 0.02\n",
      "4 0.04\n",
      "5 0.03\n",
      "6 0.06\n",
      "7 5.36\n",
      "8 1.15\n",
      "9 13.38\n",
      "10 0.12\n",
      "11 0.12\n",
      "12 0.0\n",
      "13 0.4\n",
      "14 0.17\n",
      "15 0.28\n",
      "16 5.71\n",
      "17 1.01\n",
      "18 0.48\n",
      "19 0.23\n",
      "20 0.55\n",
      "21 0.77\n",
      "22 0.24\n",
      "23 0.04\n",
      "24 3.06\n",
      "25 0.37\n",
      "26 0.19\n",
      "27 0.0\n",
      "28 0.23\n",
      "29 0.09\n",
      "30 0.33\n",
      "31 0.12\n",
      "32 0.01\n",
      "33 0.51\n",
      "34 2.78\n",
      "35 0.43\n",
      "36 0.4\n",
      "37 3.8\n",
      "38 0.8\n",
      "39 1.13\n",
      "40 2.3\n",
      "41 0.28\n",
      "42 0.71\n",
      "43 0.22\n",
      "44 0.59\n",
      "45 0.56\n",
      "46 0.54\n",
      "47 0.37\n",
      "48 0.2\n",
      "49 0.08\n",
      "50 0.15\n",
      "51 0.39\n",
      "52 0.31\n",
      "53 0.56\n",
      "54 0.15\n",
      "55 0.11\n",
      "56 0.19\n",
      "57 0.44\n",
      "58 0.27\n",
      "59 0.34\n",
      "60 0.57\n",
      "61 0.54\n",
      "62 0.32\n",
      "63 0.52\n",
      "64 0.66\n",
      "65 0.59\n",
      "66 0.27\n",
      "67 0.26\n",
      "68 0.14\n",
      "69 0.36\n",
      "70 1.82\n",
      "71 0.34\n",
      "72 0.85\n",
      "73 0.23\n",
      "74 0.41\n",
      "75 0.72\n",
      "76 0.45\n",
      "77 0.72\n",
      "78 0.78\n",
      "79 0.72\n",
      "80 0.11\n",
      "81 0.05\n",
      "82 0.06\n",
      "83 0.11\n",
      "84 0.17\n",
      "85 0.64\n",
      "86 0.45\n",
      "87 0.27\n",
      "88 0.15\n",
      "89 0.17\n",
      "90 0.3\n",
      "91 0.17\n",
      "92 0.09\n",
      "93 0.09\n",
      "94 0.06\n",
      "95 0.29\n",
      "96 0.09\n",
      "97 5.29\n",
      "98 0.71\n",
      "99 1.72\n",
      "100 0.4\n",
      "101 1.16\n",
      "102 0.73\n",
      "103 0.26\n",
      "104 0.07\n",
      "105 0.52\n",
      "106 0.38\n",
      "107 0.52\n",
      "108 0.31\n",
      "109 0.07\n",
      "110 0.36\n",
      "111 0.29\n",
      "112 0.23\n",
      "113 0.14\n",
      "114 0.74\n",
      "115 1.02\n",
      "116 0.24\n",
      "117 0.33\n",
      "118 0.17\n",
      "119 0.87\n",
      "120 0.3\n",
      "121 0.24\n",
      "122 0.0\n",
      "123 0.87\n",
      "124 0.29\n",
      "125 0.24\n",
      "126 0.27\n",
      "127 0.27\n",
      "128 0.03\n",
      "129 0.23\n",
      "130 0.3\n",
      "131 0.41\n",
      "132 0.32\n",
      "133 0.32\n",
      "134 0.18\n",
      "135 0.14\n",
      "136 0.12\n",
      "137 0.21\n",
      "138 0.0\n",
      "139 0.08\n",
      "140 0.0\n",
      "141 0.03\n",
      "142 0.22\n",
      "143 0.18\n",
      "144 0.33\n",
      "145 0.07\n",
      "146 0.13\n",
      "147 0.2\n",
      "148 0.29\n",
      "149 0.19\n",
      "150 0.61\n",
      "151 0.33\n",
      "152 1.05\n",
      "153 0.23\n",
      "154 0.0\n",
      "155 0.51\n",
      "156 0.32\n",
      "157 0.37\n",
      "158 0.48\n",
      "159 0.23\n",
      "160 0.03\n",
      "161 0.15\n",
      "162 0.21\n",
      "163 0.21\n",
      "164 0.25\n",
      "165 1.77\n",
      "166 0.18\n",
      "167 0.45\n",
      "168 0.0\n",
      "169 0.05\n"
     ]
    }
   ],
   "source": [
    "for index, val in enumerate(feature_imp):\n",
    "    print(index, round((val * 100), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e2286",
   "metadata": {},
   "source": [
    "##### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48f1ce92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a736ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923333333333333"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rf = rf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f188ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.99      1.00      1.00     17702\n",
      "         pos       0.93      0.58      0.71       298\n",
      "\n",
      "    accuracy                           0.99     18000\n",
      "   macro avg       0.96      0.79      0.85     18000\n",
      "weighted avg       0.99      0.99      0.99     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c659d8",
   "metadata": {},
   "source": [
    "##### Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c746792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9914444444444445"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = BaggingClassifier(rf, random_state=0).fit(X_train, y_train)\n",
    "cls.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7f93581",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_clf = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14dcdc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9914444444444445"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b87b648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.99      1.00      1.00     17702\n",
      "         pos       0.93      0.52      0.67       298\n",
      "\n",
      "    accuracy                           0.99     18000\n",
      "   macro avg       0.96      0.76      0.83     18000\n",
      "weighted avg       0.99      0.99      0.99     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed6572",
   "metadata": {},
   "source": [
    "##### Extra Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4513ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9908888888888889"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree = ExtraTreeClassifier(random_state=0)\n",
    "cls_extra = BaggingClassifier(extra_tree, random_state=0).fit(X_train, y_train)\n",
    "cls_extra.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ac36be",
   "metadata": {},
   "source": [
    "##### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40a560db",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = ExtraTreeClassifier(random_state=0)\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = DecisionTreeClassifier()\n",
    "clf4 = LogisticRegression()\n",
    "clf5 = SVC(C = 1.2, gamma =  0.9, kernel= 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f154b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf1 = VotingClassifier(estimators=[\n",
    "    ('ETC', clf1), ('RF', clf2), ('DT', clf3),('Log_Reg', clf4),('SVC', clf5),('Bagging',cls),], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb415193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg' 'neg' 'neg' ... 'neg' 'neg' 'neg']\n"
     ]
    }
   ],
   "source": [
    "eclf1 = eclf1.fit(X, Y)\n",
    "print(eclf1.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be10746",
   "metadata": {},
   "source": [
    "##### Boosting Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdddec7",
   "metadata": {},
   "source": [
    "##### Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce5526be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_model = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34750874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "225f61ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ada = ada_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa91cf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904444444444445"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d82633b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.99      1.00      1.00     17702\n",
      "         pos       0.76      0.61      0.68       298\n",
      "\n",
      "    accuracy                           0.99     18000\n",
      "   macro avg       0.88      0.81      0.84     18000\n",
      "weighted avg       0.99      0.99      0.99     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e156d56b",
   "metadata": {},
   "source": [
    "##### Gradient Boosting Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20960c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GB_model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e35c6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6271e987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904444444444445"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_gb = ada_model.predict(X_test)\n",
    "accuracy_score(y_test,y_pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2cb90473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.99      1.00      1.00     17702\n",
      "         pos       0.76      0.61      0.68       298\n",
      "\n",
      "    accuracy                           0.99     18000\n",
      "   macro avg       0.88      0.81      0.84     18000\n",
      "weighted avg       0.99      0.99      0.99     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af522698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
